{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN_in _keras.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vaibhavmishra1/Deep_Learning_with_Keras/blob/master/DCGAN_in__keras.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CUb13DsaFY5I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 783
        },
        "outputId": "caf980e9-583c-415d-d2d3-e83d384fdae8"
      },
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "import numpy as np\n",
        "latent_dim = 32\n",
        "height = 32\n",
        "width = 32\n",
        "channels = 3\n",
        "generator_input = keras.Input(shape=(latent_dim,))\n",
        "x = layers.Dense(128 * 16 * 16)(generator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Reshape((16, 16, 128))(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2DTranspose(256, 4, strides=2, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(256, 5, padding='same')(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(channels, 7, activation='tanh', padding='same')(x)\n",
        "generator = keras.models.Model(generator_input, x)\n",
        "generator.summary()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0813 08:46:51.473556 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "W0813 08:46:51.515827 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "W0813 08:46:51.523826 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 32)                0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 32768)             1081344   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_1 (LeakyReLU)    (None, 32768)             0         \n",
            "_________________________________________________________________\n",
            "reshape_1 (Reshape)          (None, 16, 16, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 16, 16, 256)       819456    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_2 (LeakyReLU)    (None, 16, 16, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTr (None, 32, 32, 256)       1048832   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_3 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_4 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 32, 32, 256)       1638656   \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_5 (LeakyReLU)    (None, 32, 32, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 32, 32, 3)         37635     \n",
            "=================================================================\n",
            "Total params: 6,264,579\n",
            "Trainable params: 6,264,579\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o63La3p3Fifr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 819
        },
        "outputId": "4fc71e05-d5d1-43c9-cd79-b71752dad866"
      },
      "source": [
        "discriminator_input = layers.Input(shape=(height, width, channels))\n",
        "x = layers.Conv2D(128, 3)(discriminator_input)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Conv2D(128, 4, strides=2)(x)\n",
        "x = layers.LeakyReLU()(x)\n",
        "x = layers.Flatten()(x)\n",
        "x = layers.Dropout(0.4)(x)\n",
        "x = layers.Dense(1, activation='sigmoid')(x)\n",
        "discriminator = keras.models.Model(discriminator_input, x)\n",
        "discriminator.summary()\n",
        "discriminator_optimizer = keras.optimizers.RMSprop(\n",
        "lr=0.0008,\n",
        "clipvalue=1.0,\n",
        "decay=1e-8)\n",
        "discriminator.compile(optimizer=discriminator_optimizer,\n",
        "loss='binary_crossentropy')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0813 08:46:53.753347 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "W0813 08:46:53.767394 139759532959616 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "W0813 08:46:53.829383 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "W0813 08:46:53.840934 139759532959616 deprecation_wrapper.py:119] From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "W0813 08:46:53.849834 139759532959616 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         (None, 32, 32, 3)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 30, 30, 128)       3584      \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_6 (LeakyReLU)    (None, 30, 30, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_6 (Conv2D)            (None, 14, 14, 128)       262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_7 (LeakyReLU)    (None, 14, 14, 128)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_7 (Conv2D)            (None, 6, 6, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_8 (LeakyReLU)    (None, 6, 6, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 2, 2, 128)         262272    \n",
            "_________________________________________________________________\n",
            "leaky_re_lu_9 (LeakyReLU)    (None, 2, 2, 128)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 790,913\n",
            "Trainable params: 790,913\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y0t5hQcHFwB4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "discriminator.trainable = False\n",
        "gan_input = keras.Input(shape=(latent_dim,))\n",
        "gan_output = discriminator(generator(gan_input))\n",
        "gan = keras.models.Model(gan_input, gan_output)\n",
        "gan_optimizer = keras.optimizers.RMSprop(lr=0.0004, clipvalue=1.0, decay=1e-8)\n",
        "gan.compile(optimizer=gan_optimizer, loss='binary_crossentropy')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2P7ylk0PFzjw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f8507fcf-8191-4c04-d5e2-2edef33d589c"
      },
      "source": [
        "import os\n",
        "from keras.preprocessing import image\n",
        "(x_train, y_train), (_, _) = keras.datasets.cifar10.load_data()\n",
        "x_train = x_train[y_train.flatten() == 6]\n",
        "x_train = x_train.reshape(\n",
        "(x_train.shape[0],) +\n",
        "(height, width, channels)).astype('float32') / 255.\n",
        "iterations = 10000\n",
        "batch_size = 20\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-eTvxTg9GHBp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir saves\n",
        "save_dir = 'saves'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AuHLmGAwGSyO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "63257524-cdc4-4eae-b161-2b6ef6f616f7"
      },
      "source": [
        "start = 0\n",
        "import matplotlib.pyplot as plt\n",
        "for step in range(iterations):\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,\n",
        "  latent_dim))\n",
        "  generated_images = generator.predict(random_latent_vectors)\n",
        "  stop = start + batch_size\n",
        "  real_images = x_train[start: stop]\n",
        "  combined_images = np.concatenate([generated_images, real_images])\n",
        "  labels = np.concatenate([np.ones((batch_size, 1)),\n",
        "  np.zeros((batch_size, 1))])\n",
        "  labels += 0.05 * np.random.random(labels.shape)\n",
        "  d_loss = discriminator.train_on_batch(combined_images, labels)\n",
        "  random_latent_vectors = np.random.normal(size=(batch_size,\n",
        "  latent_dim))\n",
        "  misleading_targets = np.zeros((batch_size, 1))\n",
        "  a_loss = gan.train_on_batch(random_latent_vectors,\n",
        "  misleading_targets)\n",
        "  start += batch_size\n",
        "  if start > len(x_train) - batch_size:\n",
        "    start = 0\n",
        "  if step % 100 == 0:\n",
        "    gan.save_weights('gan.h5')\n",
        "    print('discriminator loss:', d_loss)\n",
        "    print('adversarial loss:', a_loss)\n",
        "    img = image.array_to_img(generated_images[0] * 255., scale=False)\n",
        "    plt.imshow(img)\n",
        "    plt.savefig('generated_frog' + str(step) + '.png')\n",
        "    img = image.array_to_img(real_images[0] * 255., scale=False)\n",
        "    plt.imshow(img)\n",
        "    plt.savefig('real_frog' + str(step) + '.png')\n",
        "    "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator loss: 0.6931291\n",
            "adversarial loss: 0.67113674\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/keras/engine/training.py:490: UserWarning: Discrepancy between trainable weights and collected trainable weights, did you set `model.trainable` without calling `model.compile` after ?\n",
            "  'Discrepancy between trainable weights and collected trainable'\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "discriminator loss: 0.69762486\n",
            "adversarial loss: 0.89682806\n",
            "discriminator loss: 0.69219345\n",
            "adversarial loss: 0.9495556\n",
            "discriminator loss: 0.70194983\n",
            "adversarial loss: 0.7373932\n",
            "discriminator loss: 0.694542\n",
            "adversarial loss: 0.73752964\n",
            "discriminator loss: 0.69554883\n",
            "adversarial loss: 0.76189804\n",
            "discriminator loss: 0.6838101\n",
            "adversarial loss: 0.79036295\n",
            "discriminator loss: 0.7078579\n",
            "adversarial loss: 0.72401327\n",
            "discriminator loss: 0.70348054\n",
            "adversarial loss: 0.725625\n",
            "discriminator loss: 0.8208586\n",
            "adversarial loss: 0.7690609\n",
            "discriminator loss: 0.7039604\n",
            "adversarial loss: 0.7485563\n",
            "discriminator loss: 0.6927434\n",
            "adversarial loss: 0.74921536\n",
            "discriminator loss: 0.69068146\n",
            "adversarial loss: 0.7721928\n",
            "discriminator loss: 0.6870719\n",
            "adversarial loss: 0.74825394\n",
            "discriminator loss: 0.69501865\n",
            "adversarial loss: 0.74291664\n",
            "discriminator loss: 0.6839528\n",
            "adversarial loss: 0.7384181\n",
            "discriminator loss: 0.8123123\n",
            "adversarial loss: 0.73834395\n",
            "discriminator loss: 0.68423647\n",
            "adversarial loss: 0.8090251\n",
            "discriminator loss: 0.9120377\n",
            "adversarial loss: 0.785666\n",
            "discriminator loss: 0.7533207\n",
            "adversarial loss: 0.7562755\n",
            "discriminator loss: 0.69455945\n",
            "adversarial loss: 0.73569345\n",
            "discriminator loss: 0.6747979\n",
            "adversarial loss: 0.68476564\n",
            "discriminator loss: 0.71604383\n",
            "adversarial loss: 0.77955\n",
            "discriminator loss: 0.70065975\n",
            "adversarial loss: 0.764606\n",
            "discriminator loss: 0.69807285\n",
            "adversarial loss: 0.7550599\n",
            "discriminator loss: 0.6950892\n",
            "adversarial loss: 0.7251487\n",
            "discriminator loss: 0.68836796\n",
            "adversarial loss: 0.7218946\n",
            "discriminator loss: 0.6880423\n",
            "adversarial loss: 0.802776\n",
            "discriminator loss: 0.7018361\n",
            "adversarial loss: 0.73747575\n",
            "discriminator loss: 0.69937456\n",
            "adversarial loss: 0.79395634\n",
            "discriminator loss: 0.6954602\n",
            "adversarial loss: 0.7736823\n",
            "discriminator loss: 0.700842\n",
            "adversarial loss: 0.7719852\n",
            "discriminator loss: 0.68517005\n",
            "adversarial loss: 0.74814904\n",
            "discriminator loss: 0.6851202\n",
            "adversarial loss: 0.725402\n",
            "discriminator loss: 0.6943387\n",
            "adversarial loss: 0.7474473\n",
            "discriminator loss: 0.69483966\n",
            "adversarial loss: 0.76233566\n",
            "discriminator loss: 0.69892013\n",
            "adversarial loss: 0.78304386\n",
            "discriminator loss: 0.70323676\n",
            "adversarial loss: 0.7644736\n",
            "discriminator loss: 0.6840361\n",
            "adversarial loss: 0.73706484\n",
            "discriminator loss: 0.6832348\n",
            "adversarial loss: 0.73276824\n",
            "discriminator loss: 0.69301903\n",
            "adversarial loss: 0.710584\n",
            "discriminator loss: 0.69697386\n",
            "adversarial loss: 0.752455\n",
            "discriminator loss: 0.69297284\n",
            "adversarial loss: 0.7513064\n",
            "discriminator loss: 0.7115649\n",
            "adversarial loss: 0.72431934\n",
            "discriminator loss: 0.69980395\n",
            "adversarial loss: 0.69169587\n",
            "discriminator loss: 0.6930324\n",
            "adversarial loss: 0.7575363\n",
            "discriminator loss: 0.6961525\n",
            "adversarial loss: 0.7762735\n",
            "discriminator loss: 0.68740577\n",
            "adversarial loss: 0.80140895\n",
            "discriminator loss: 0.70489895\n",
            "adversarial loss: 0.73216164\n",
            "discriminator loss: 0.6940847\n",
            "adversarial loss: 0.7258374\n",
            "discriminator loss: 0.67614734\n",
            "adversarial loss: 0.77419657\n",
            "discriminator loss: 0.92431915\n",
            "adversarial loss: 0.7723557\n",
            "discriminator loss: 0.68725514\n",
            "adversarial loss: 0.7642699\n",
            "discriminator loss: 0.7058401\n",
            "adversarial loss: 0.76371527\n",
            "discriminator loss: 0.6935649\n",
            "adversarial loss: 0.73687094\n",
            "discriminator loss: 0.7409011\n",
            "adversarial loss: 0.7552728\n",
            "discriminator loss: 0.7107855\n",
            "adversarial loss: 0.7433204\n",
            "discriminator loss: 0.7010026\n",
            "adversarial loss: 0.7744432\n",
            "discriminator loss: 0.6874715\n",
            "adversarial loss: 0.72681427\n",
            "discriminator loss: 0.69322747\n",
            "adversarial loss: 0.76279444\n",
            "discriminator loss: 0.69274366\n",
            "adversarial loss: 0.739516\n",
            "discriminator loss: 0.6875512\n",
            "adversarial loss: 0.74271995\n",
            "discriminator loss: 0.68967974\n",
            "adversarial loss: 0.7665916\n",
            "discriminator loss: 0.7114614\n",
            "adversarial loss: 0.7439853\n",
            "discriminator loss: 0.69748276\n",
            "adversarial loss: 0.6933404\n",
            "discriminator loss: 0.68846345\n",
            "adversarial loss: 0.7722009\n",
            "discriminator loss: 0.71173954\n",
            "adversarial loss: 0.7530363\n",
            "discriminator loss: 0.6846962\n",
            "adversarial loss: 0.7655254\n",
            "discriminator loss: 0.70970124\n",
            "adversarial loss: 0.79389066\n",
            "discriminator loss: 0.7044782\n",
            "adversarial loss: 0.7551139\n",
            "discriminator loss: 0.6886283\n",
            "adversarial loss: 0.71094847\n",
            "discriminator loss: 0.70049185\n",
            "adversarial loss: 0.7400723\n",
            "discriminator loss: 0.6989509\n",
            "adversarial loss: 1.0807765\n",
            "discriminator loss: 0.6932524\n",
            "adversarial loss: 0.74589425\n",
            "discriminator loss: 0.6817421\n",
            "adversarial loss: 0.8571026\n",
            "discriminator loss: 0.70278484\n",
            "adversarial loss: 0.740864\n",
            "discriminator loss: 0.6861763\n",
            "adversarial loss: 0.77576256\n",
            "discriminator loss: 0.70746547\n",
            "adversarial loss: 0.7478351\n",
            "discriminator loss: 0.6903302\n",
            "adversarial loss: 0.8239436\n",
            "discriminator loss: 0.69154483\n",
            "adversarial loss: 0.8104126\n",
            "discriminator loss: 0.6993908\n",
            "adversarial loss: 0.74981004\n",
            "discriminator loss: 0.6982316\n",
            "adversarial loss: 0.75595176\n",
            "discriminator loss: 0.7031431\n",
            "adversarial loss: 0.90245163\n",
            "discriminator loss: 0.724784\n",
            "adversarial loss: 0.77154577\n",
            "discriminator loss: 0.69621795\n",
            "adversarial loss: 0.7245544\n",
            "discriminator loss: 0.69690895\n",
            "adversarial loss: 0.703948\n",
            "discriminator loss: 0.67537326\n",
            "adversarial loss: 2.2576783\n",
            "discriminator loss: 0.69433296\n",
            "adversarial loss: 0.7175064\n",
            "discriminator loss: 0.6743437\n",
            "adversarial loss: 0.74325347\n",
            "discriminator loss: 0.6887924\n",
            "adversarial loss: 0.77649075\n",
            "discriminator loss: 0.68014914\n",
            "adversarial loss: 0.73788863\n",
            "discriminator loss: 0.70657474\n",
            "adversarial loss: 0.8748821\n",
            "discriminator loss: 0.67686284\n",
            "adversarial loss: 0.77314186\n",
            "discriminator loss: 0.69938517\n",
            "adversarial loss: 0.7852043\n",
            "discriminator loss: 0.6914875\n",
            "adversarial loss: 0.8365412\n",
            "discriminator loss: 0.69656765\n",
            "adversarial loss: 0.82389706\n",
            "discriminator loss: 0.6953686\n",
            "adversarial loss: 0.797751\n",
            "discriminator loss: 0.6868593\n",
            "adversarial loss: 0.8047075\n",
            "discriminator loss: 0.6852111\n",
            "adversarial loss: 0.8072672\n",
            "discriminator loss: 0.71635354\n",
            "adversarial loss: 0.86874694\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nzi9Eosj5hUgUOb8QifL/AGTCKKpDcExKAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGD9TWtLIqL6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}